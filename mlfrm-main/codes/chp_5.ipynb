{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "from scipy.stats import norm\n",
    "import requests\n",
    "from io import StringIO\n",
    "import seaborn as sns; sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "std_dev = 1\n",
    "x = np.arange(-5, 5, 0.01)\n",
    "y = norm.pdf(x, mean, std_dev)\n",
    "pdf = plt.plot(x, y)\n",
    "min_ylim, max_ylim = plt.ylim()\n",
    "plt.text(np.percentile(x, 5), max_ylim * 0.9, '95%:${:.4f}'\n",
    "         .format(np.percentile(x, 5)))\n",
    "plt.axvline(np.percentile(x, 5), color='r', linestyle='dashed',\n",
    "            linewidth=4)\n",
    "plt.title('Value at Risk Illustration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDailyData(symbol):\n",
    "        parameters = {'function': 'TIME_SERIES_DAILY_ADJUSTED', \n",
    "                      'symbol': symbol,\n",
    "                       'outputsize':'full',\n",
    "                       'datatype': 'csv', \n",
    "                       'apikey': 'insert your api key here'}\n",
    "\n",
    "        response = requests.get('https://www.alphavantage.co/query',\n",
    "                                params=parameters)\n",
    "\n",
    "        csvText = StringIO(response.text)\n",
    "        data = pd.read_csv(csvText, index_col='timestamp')\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [\"IBM\", \"MSFT\", \"INTC\"]\n",
    "stock3 = []\n",
    "for symbol in symbols:\n",
    "    stock3.append(getDailyData(symbol)[::-1]['close']\n",
    "                  ['2020-01-01': '2020-12-31'])\n",
    "stocks = pd.DataFrame(stock3).T\n",
    "stocks.columns = symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance-Covariance Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_returns = (np.log(stocks) - np.log(stocks.shift(1))).dropna()\n",
    "stocks_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_returns_mean = stocks_returns.mean()\n",
    "weights  = np.random.random(len(stocks_returns.columns))\n",
    "weights /= np.sum(weights)\n",
    "cov_var = stocks_returns.cov()\n",
    "port_std = np.sqrt(weights.T.dot(cov_var).dot(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_investment = 1e6\n",
    "conf_level = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VaR_parametric(initial_investment, conf_level):\n",
    "    alpha = norm.ppf(1 - conf_level, stocks_returns_mean, port_std)\n",
    "    for i, j in zip(stocks.columns, range(len(stocks.columns))):\n",
    "        VaR_param = (initial_investment - initial_investment * \n",
    "                     (1 + alpha))[j]\n",
    "        print(\"Parametric VaR result for {} is {} \"\n",
    "              .format(i, VaR_param))\n",
    "    VaR_param = (initial_investment - initial_investment * (1 + alpha))\n",
    "    print('--' * 25)\n",
    "    return VaR_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VaR_param = VaR_parametric(initial_investment, conf_level)\n",
    "VaR_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var_horizon = []\n",
    "time_horizon = 30\n",
    "for j in range(len(stocks_returns.columns)):\n",
    "    for i in range(1, time_horizon + 1):\n",
    "        var_horizon.append(VaR_param[j] * np.sqrt(i))\n",
    "plt.plot(var_horizon[:time_horizon], \"o\",\n",
    "         c='blue', marker='*', label='IBM')\n",
    "plt.plot(var_horizon[time_horizon:time_horizon + 30], \"o\",\n",
    "         c='green', marker='o', label='MSFT')\n",
    "plt.plot(var_horizon[time_horizon + 30:time_horizon + 60], \"o\",\n",
    "         c='red', marker='v', label='INTC')\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"USD\")\n",
    "plt.title(\"VaR over 30-day period\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Simulation VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VaR_historical(initial_investment, conf_level):\n",
    "    Hist_percentile95 = []\n",
    "    for i, j in zip(stocks_returns.columns,\n",
    "                    range(len(stocks_returns.columns))):\n",
    "        Hist_percentile95.append(np.percentile(stocks_returns.loc[:, i],\n",
    "                                               5))\n",
    "        print(\"Based on historical values 95% of {}'s return is {:.4f}\"\n",
    "              .format(i, Hist_percentile95[j]))\n",
    "        VaR_historical = (initial_investment - initial_investment *\n",
    "                          (1 + Hist_percentile95[j]))\n",
    "        print(\"Historical VaR result for {} is {:.2f} \"\n",
    "              .format(i, VaR_historical))\n",
    "        print('--' * 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VaR_historical(initial_investment,conf_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(-1, 1, 100) \n",
    "y = np.random.uniform(-1, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 100    \n",
    "def pi_calc(x, y):\n",
    "    point_inside_circle = 0\n",
    "    for i in range(sample):\n",
    "        if np.sqrt(x[i] ** 2 + y[i] ** 2) <= 1:\n",
    "            point_inside_circle += 1 \n",
    "    print('pi value is {}'.format(4 * point_inside_circle/sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_calc(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(-1, 1, 1000000)\n",
    "y = np.random.uniform(-1, 1, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 1000000   \n",
    "\n",
    "def pi_calc(x, y):\n",
    "    point_inside_circle = 0\n",
    "    for i in range(sample):\n",
    "        if np.sqrt(x[i] ** 2 + y[i] ** 2) < 1:\n",
    "            point_inside_circle += 1 \n",
    "    print('pi value is {:.2f}'.format(4 * point_inside_circle/sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_calc(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = pd.DataFrame([])\n",
    "num_reps = 1000\n",
    "n = 100\n",
    "for i in range(len(stocks.columns)):\n",
    "    mean = np.random.randn(n).mean()\n",
    "    std = np.random.randn(n).std()\n",
    "    temp = pd.DataFrame(np.random.normal(mean, std, num_reps))\n",
    "    sim_data = pd.concat([sim_data, temp], axis=1)\n",
    "sim_data.columns = ['Simulation 1', 'Simulation 2', 'Simulation 3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_VaR(initial_investment, conf_level):\n",
    "    MC_percentile95 = []\n",
    "    for i, j in zip(sim_data.columns, range(len(sim_data.columns))):\n",
    "        MC_percentile95.append(np.percentile(sim_data.loc[:, i], 5))\n",
    "        print(\"Based on simulation 95% of {}'s return is {:.4f}\"\n",
    "              .format(i, MC_percentile95[j]))\n",
    "        VaR_MC = (initial_investment - initial_investment * \n",
    "                  (1 + MC_percentile95[j]))\n",
    "        print(\"Simulation VaR result for {} is {:.2f} \"\n",
    "              .format(i, VaR_MC))\n",
    "        print('--' * 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_VaR(initial_investment, conf_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Marcenko-Pastur Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_pdf(sigma2, q, obs):\n",
    "    lambda_plus = sigma2 * (1 + q ** 0.5) ** 2\n",
    "    lambda_minus = sigma2 * (1 - q ** 0.5) ** 2\n",
    "    l = np.linspace(lambda_minus, lambda_plus, obs)\n",
    "    pdf_mp = 1 / (2 * np.pi * sigma2 * q * l) \\\n",
    "             * np.sqrt((lambda_plus  - l) \n",
    "             *  (l - lambda_minus))\n",
    "    pdf_mp = pd.Series(pdf_mp, index=l)\n",
    "    return pdf_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def kde_fit(bandwidth,obs,x=None):\n",
    "    kde = KernelDensity(bandwidth, kernel='gaussian')\n",
    "    if len(obs.shape) == 1:\n",
    "        kde_fit=kde.fit(np.array(obs).reshape(-1, 1))\n",
    "    if x is None:\n",
    "        x=np.unique(obs).reshape(-1, 1)\n",
    "    if len(x.shape) == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "    logprob = kde_fit.score_samples(x)\n",
    "    pdf_kde = pd.Series(np.exp(logprob), index=x.flatten())\n",
    "    return pdf_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = np.random.normal(size=(10000, 1000))\n",
    "corr_coef = np.corrcoef(corr_mat, rowvar=0)\n",
    "sigma2 = 1\n",
    "obs = corr_mat.shape[0]\n",
    "q = corr_mat.shape[0] / corr_mat.shape[1]\n",
    "\n",
    "def plotting(corr_coef, q):\n",
    "    ev, _ = np.linalg.eigh(corr_coef)\n",
    "    idx = ev.argsort()[::-1]\n",
    "    eigen_val = np.diagflat(ev[idx])\n",
    "    pdf_mp = mp_pdf(1., q=corr_mat.shape[1] / corr_mat.shape[0],\n",
    "                    obs=1000)\n",
    "    kde_pdf = kde_fit(0.01, np.diag(eigen_val))\n",
    "    ax = pdf_mp.plot(title=\"Marchenko-Pastur Theorem\",\n",
    "                     label=\"M-P\", style='r--')\n",
    "    kde_pdf.plot(label=\"Empirical Density\", style='o-', alpha=0.3)\n",
    "    ax.set(xlabel=\"Eigenvalue\", ylabel=\"Frequency\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(corr_coef, q);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import portfoliolab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_estimators = pl.estimators.RiskEstimators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices = stocks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = stocks_returns.cov()\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_relation = stock_prices.shape[0] / stock_prices.shape[1]\n",
    "kde_bwidth = 0.25\n",
    "cov_matrix_denoised = risk_estimators.denoise_covariance(cov_matrix,\n",
    "                                                         tn_relation,\n",
    "                                                         kde_bwidth)\n",
    "cov_matrix_denoised = pd.DataFrame(cov_matrix_denoised,\n",
    "                                   index=cov_matrix.index,\n",
    "                                   columns=cov_matrix.columns)\n",
    "cov_matrix_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VaR_parametric_denoised(initial_investment, conf_level):\n",
    "    port_std = np.sqrt(weights.T.dot(cov_matrix_denoised)\n",
    "                       .dot(weights))\n",
    "    alpha = norm.ppf(1 - conf_level, stocks_returns_mean, port_std)\n",
    "    for i, j in zip(stocks.columns,range(len(stocks.columns))):\n",
    "        print(\"Parametric VaR result for {} is {} \".format(i,VaR_param))\n",
    "    VaR_params = (initial_investment - initial_investment * (1 + alpha))\n",
    "    print('--' * 25)\n",
    "    return VaR_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VaR_parametric_denoised(initial_investment, conf_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [\"IBM\", \"MSFT\", \"INTC\"]\n",
    "stock3 = []\n",
    "for symbol in symbols:\n",
    "    stock3.append(getDailyData(symbol)[::-1]['close']\n",
    "                  ['2007-04-01': '2009-02-01'])\n",
    "stocks_crisis = pd.DataFrame(stock3).T\n",
    "stocks_crisis.columns = symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices = stocks_crisis.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_returns = (np.log(stocks) - np.log(stocks.shift(1))).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = stocks_returns.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VaR_parametric(initial_investment, conf_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VaR_parametric_denoised(initial_investment, conf_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Sub-additivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset1 = [-0.5, 0, 0.1, 0.4]\n",
    "VaR1 = np.percentile(asset1, 90)\n",
    "print('VaR for the Asset 1 is {:.4f}'.format(VaR1))\n",
    "asset2 = [0, -0.5, 0.01, 0.4]\n",
    "VaR2 = np.percentile(asset2, 90)\n",
    "print('VaR for the Asset 2 is {:.4f}'.format(VaR2))\n",
    "VaR_all = np.percentile(asset1 + asset2, 90)\n",
    "print('VaR for the portfolio is {:.4f}'.format(VaR_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset1 = [-0.5, 0, 0.05, 0.03]\n",
    "VaR1 = np.percentile(asset1, 90)\n",
    "print('VaR for the Asset 1 is {:.4f}'.format(VaR1))\n",
    "asset2 = [0, -0.5, 0.02, 0.8]\n",
    "VaR2 = np.percentile(asset2,90)\n",
    "print('VaR for the Asset 2 is {:.4f}'.format(VaR2))\n",
    "VaR_all = np.percentile(asset1 + asset2 , 90)\n",
    "print('VaR for the portfolio is {:.4f}'.format(VaR_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Shortfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES_parametric(initial_investment , conf_level):\n",
    "    alpha = - norm.ppf(1 - conf_level,stocks_returns_mean,port_std)\n",
    "    for i, j in zip(stocks.columns, range(len(stocks.columns))):\n",
    "        VaR_param = (initial_investment * alpha)[j]\n",
    "        ES_param = (1 / (1 - conf_level)) \\\n",
    "                   * initial_investment \\\n",
    "                   * norm.expect(lambda x: x,\n",
    "                                 lb = norm.ppf(conf_level,\n",
    "                                               stocks_returns_mean[j],\n",
    "                                               port_std),\n",
    "                                 loc = stocks_returns_mean[j],\n",
    "                                 scale = port_std)\n",
    "        print(f\"Parametric ES result for {i} is {ES_param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_parametric(initial_investment, conf_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES_historical(initial_investment, conf_level):\n",
    "    for i, j in zip(stocks_returns.columns, \n",
    "                    range(len(stocks_returns.columns))):\n",
    "        ES_hist_percentile95 = np.percentile(stocks_returns.loc[:, i],\n",
    "                                             5)\n",
    "        ES_historical = stocks_returns[str(i)][stocks_returns[str(i)] <=\n",
    "                                               ES_hist_percentile95]\\\n",
    "                                               .mean()\n",
    "        print(\"Historical ES result for {} is {:.4f} \"\n",
    "              .format(i, initial_investment * ES_historical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_historical(initial_investment, conf_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bid-Ask Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_ask = pd.read_csv('bid_ask.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_ask['mid_price'] = (bid_ask['ASKHI'] + bid_ask['BIDLO']) / 2\n",
    "buyer_seller_initiated = []\n",
    "for i in range(len(bid_ask)):\n",
    "    if bid_ask['PRC'][i] > bid_ask['mid_price'][i]:\n",
    "        buyer_seller_initiated.append(1)\n",
    "    else:\n",
    "        buyer_seller_initiated.append(0)\n",
    "        \n",
    "bid_ask['buyer_seller_init'] = buyer_seller_initiated   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effective_cost = []\n",
    "for i in range(len(bid_ask)):\n",
    "    if bid_ask['buyer_seller_init'][i] == 1:\n",
    "        effective_cost.append((bid_ask['PRC'][i] - \n",
    "                               bid_ask['mid_price'][i]) / \n",
    "                               bid_ask['mid_price'][i])\n",
    "    else:\n",
    "        effective_cost.append((bid_ask['mid_price'][i] - \n",
    "                               bid_ask['PRC'][i])/\n",
    "                               bid_ask['mid_price'][i])\n",
    "bid_ask['effective_cost'] = effective_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_ask['quoted'] = bid_ask['ASKHI'] - bid_ask['BIDLO']\n",
    "bid_ask['prop_quoted'] = (bid_ask['ASKHI'] - bid_ask['BIDLO']) /\\\n",
    "                         bid_ask['mid_price']\n",
    "bid_ask['effective'] = 2 * abs(bid_ask['PRC'] - bid_ask['mid_price'])\n",
    "bid_ask['prop_effective'] = 2 * abs(bid_ask['PRC'] - \n",
    "                                    bid_ask['mid_price']) /\\\n",
    "                                    bid_ask['PRC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_meas = bid_ask.iloc[:, -5:]\n",
    "spread_meas.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_meas.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr = spread_meas.corr().unstack()\\\n",
    "            .sort_values(ascending=False).drop_duplicates()\n",
    "high_corr[(high_corr > 0.80) & (high_corr != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_spread_measures = bid_ask.iloc[:, -5:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sec_mean_corr = sorted_spread_measures.mean(axis=1).mean()\n",
    "std_corr = sorted_spread_measures.std().sum() / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=stocks.columns)\n",
    "last_prices = []\n",
    "for i in symbols:\n",
    "    last_prices.append(stocks[i].iloc[-1])\n",
    "df['last_prices'] = last_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES_parametric(initial_investment, conf_level):\n",
    "    ES_params = [ ]\n",
    "    alpha = - norm.ppf(1 - conf_level, stocks_returns_mean, port_std)\n",
    "    for i,j in zip(stocks.columns,range(len(stocks.columns))):\n",
    "        VaR_param = (initial_investment * alpha)[j]\n",
    "        ES_param = (1 / (1 - conf_level)) \\\n",
    "                   * norm.expect(lambda x: VaR_param, lb = conf_level)\n",
    "        ES_params.append(ES_param)\n",
    "    return ES_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ES_params = ES_parametric(initial_investment, conf_level)\n",
    "for i in range(len(symbols)):\n",
    "    print(f'The ES result for {symbols[i]} is {ES_params[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1.96\n",
    "\n",
    "for i, j in zip(range(len(symbols)), symbols):\n",
    "    print('The liquidity Adjusted ES of {} is {}'\n",
    "          .format(j, ES_params[i] + (df.loc[j].values[0] / 2) * \n",
    "                  (cross_sec_mean_corr + k * std_corr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "spread_meas_scaled = scaler.fit_transform(np.abs(spread_meas))\n",
    "pca = PCA(n_components=5)\n",
    "prin_comp = pca.fit_transform(spread_meas_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_expl = np.round(pca.explained_variance_ratio_, decimals=4)\n",
    "cum_var = np.cumsum(np.round(pca.explained_variance_ratio_,\n",
    "                             decimals=4))\n",
    "print('Individually Explained Variances are:\\n{}'.format(var_expl)) \n",
    "print('=='*30)\n",
    "print('Cumulative Explained Variances are: {}'.format(cum_var))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(np.abs(spread_meas_scaled))\n",
    "prin_comp = pca.transform(np.abs(spread_meas_scaled))\n",
    "prin_comp = pd.DataFrame(np.abs(prin_comp), columns = ['Component 1',\n",
    "                                                       'Component 2'])\n",
    "print(pca.explained_variance_ratio_*100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myplot(score, coeff, labels=None):\n",
    "    xs = score[:, 0]\n",
    "    ys = score[:, 1]\n",
    "    n = coeff.shape[0]\n",
    "    scalex = 1.0 / (xs.max() - xs.min())\n",
    "    scaley = 1.0 / (ys.max() - ys.min())\n",
    "    plt.scatter(xs * scalex * 4, ys * scaley * 4, s=5)\n",
    "    for i in range(n):\n",
    "        plt.arrow(0, 0, coeff[i, 0], coeff[i, 1], color = 'r',\n",
    "                  alpha=0.5)\n",
    "        if labels is None:\n",
    "            plt.text(coeff[i, 0], coeff[i, 1], \"Var\"+str(i),\n",
    "                     color='black')\n",
    "        else:\n",
    "            plt.text(coeff[i,0 ], coeff[i, 1], labels[i],\n",
    "                     color='black')\n",
    " \n",
    "    plt.xlabel(\"PC{}\".format(1))\n",
    "    plt.ylabel(\"PC{}\".format(2))\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_measures_scaled_df = pd.DataFrame(spread_meas_scaled,\n",
    "                                         columns=spread_meas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myplot(np.array(spread_measures_scaled_df)[:, 0:2], \n",
    "       np.transpose(pca.components_[0:2,:]), \n",
    "       list(spread_measures_scaled_df.columns))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prin_comp1_rescaled = prin_comp.iloc[:,0] * prin_comp.iloc[:,0].std()\\\n",
    "                      + prin_comp.iloc[:, 0].mean()\n",
    "prin_comp2_rescaled = prin_comp.iloc[:,1] * prin_comp.iloc[:,1].std()\\\n",
    "                      + prin_comp.iloc[:, 1].mean()\n",
    "prin_comp_rescaled = pd.concat([prin_comp1_rescaled, \n",
    "                                prin_comp2_rescaled],\n",
    "                               axis=1)\n",
    "prin_comp_rescaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pca_liq = prin_comp_rescaled.mean(axis=1).mean()\n",
    "mean_pca_liq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1.96\n",
    "for i, j in zip(range(len(symbols)), symbols):\n",
    "    print('The liquidity Adjusted ES of {} is {}'\n",
    "          .format(j, ES_params[i] + (df.loc[j].values[0] / 2) * \n",
    "                  (mean_pca_liq + k * std_corr)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
