{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data = pd.read_csv('datasets/fraudTrain.csv')\n",
    "del fraud_data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tag::Fin_ML_08_02[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(fraud_data['is_fraud'].value_counts(), labels=[0, 1])\n",
    "plt.title('Pie Chart for Dependent Variable');\n",
    "print(fraud_data['is_fraud'].value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "msno.bar(fraud_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data['time'] = pd.to_datetime(fraud_data['trans_date_trans_time'])\n",
    "del fraud_data['trans_date_trans_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data['days'] = fraud_data['time'].dt.day_name()\n",
    "fraud_data['hour'] = fraud_data['time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraud_cat(cols):\n",
    "    k = 1\n",
    "    plt.figure(figsize=(20, 40))\n",
    "    for i in cols:\n",
    "        categ = fraud_data.loc[fraud_data['is_fraud'] == 1, i].\\\n",
    "                value_counts().sort_values(ascending=False).\\\n",
    "                reset_index().head(10)#<1>\n",
    "        plt.subplot(len(cols) / 2, len(cols) / 2, k)\n",
    "        bar_plot = plt.bar(categ.iloc[:, 0], categ[i])\n",
    "        plt.title(f'Cases per {i} Categories')\n",
    "        plt.xticks(rotation='45')\n",
    "        k+= 1\n",
    "    return categ, bar_plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['job', 'state', 'gender', 'category', 'days', 'hour']\n",
    "_, bar_plot = fraud_cat(cols)\n",
    "bar_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['amt','gender','state','category',\n",
    "      'city_pop','job','is_fraud','days','hour']\n",
    "fraud_data_df=fraud_data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=fraud_data[cols].select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoded_cat(data, cat_cols):\n",
    "    for i in cat_cols:\n",
    "        df1 = pd.get_dummies(data[str(i)], \n",
    "                             prefix=i, drop_first=True)\n",
    "        data.drop(str(i), axis=1, inplace=True)\n",
    "        data = pd.concat([data, df1], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fraud_df = one_hot_encoded_cat(fraud_data_df, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = fraud_data_df.select_dtypes(exclude='object').columns\n",
    "fraud_data_df = fraud_data_df[num_col]\n",
    "del fraud_data_df['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "corrmat = fraud_data_df.corr()\n",
    "top_corr_features = corrmat.index\n",
    "heat_map = sns.heatmap(corrmat, annot=True, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import (classification_report,\n",
    "                            confusion_matrix, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_fraud_class = fraud_df[fraud_df['is_fraud'] == 0]\n",
    "fraud_class = fraud_df[fraud_df['is_fraud'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_fraud_count,fraud_count=fraud_df['is_fraud'].value_counts()\n",
    "print('The number of observations in non_fraud_class:', non_fraud_count)\n",
    "print('The number of observations in fraud_class:', fraud_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_fraud_under = non_fraud_class.sample(fraud_count)\n",
    "under_sampled = pd.concat([non_fraud_under, fraud_class], axis=0)\n",
    "X_under = under_sampled.drop('is_fraud',axis=1)\n",
    "y_under = under_sampled['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_under, X_test_under, y_train_under, y_test_under =\\\n",
    "        train_test_split(X_under, y_under, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_log = {'C': np.logspace(-4, 4, 4), 'penalty': ['l1', 'l2']}\n",
    "log_grid = GridSearchCV(LogisticRegression(),\n",
    "                        param_grid=param_log, n_jobs=-1)\n",
    "log_grid.fit(X_train_under, y_train_under)\n",
    "prediction_log = log_grid.predict(X_test_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_log = confusion_matrix(y_true=y_test_under,\n",
    "                                y_pred=prediction_log)\n",
    "print('Confusion matrix:\\n', conf_mat_log)\n",
    "print('--' * 25)\n",
    "print('Classification report:\\n',\n",
    "      classification_report(y_test_under, prediction_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dt = {'max_depth': [3, 5, 10],\n",
    "            'min_samples_split': [2, 4, 6],\n",
    "            'criterion': ['gini', 'entropy']}\n",
    "dt_grid = GridSearchCV(DecisionTreeClassifier(),\n",
    "                       param_grid=param_dt, n_jobs=-1)\n",
    "dt_grid.fit(X_train_under, y_train_under)\n",
    "prediction_dt = dt_grid.predict(X_test_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_dt = confusion_matrix(y_true=y_test_under,\n",
    "                               y_pred=prediction_dt)\n",
    "print('Confusion matrix:\\n', conf_mat_dt)\n",
    "print('--' * 25)\n",
    "print('Classification report:\\n',\n",
    "      classification_report(y_test_under, prediction_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rf = {'n_estimators':[20,50,100] ,\n",
    "         'max_depth':[3,5,10],\n",
    "         'min_samples_split':[2,4,6],\n",
    "         'max_features':['auto', 'sqrt', 'log2']}  \n",
    "rf_grid = GridSearchCV(RandomForestClassifier(),\n",
    "                      param_grid=param_rf, n_jobs=-1)\n",
    "rf_grid.fit(X_train_under, y_train_under)\n",
    "prediction_rf = rf_grid.predict(X_test_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf_mat_rf = confusion_matrix(y_true=y_test_under,\n",
    "                               y_pred=prediction_rf)\n",
    "print('Confusion matrix:\\n', conf_mat_rf)\n",
    "print('--' * 25)\n",
    "print('Classification report:\\n', \n",
    "      classification_report(y_test_under, prediction_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_boost = {'learning_rate': [0.01, 0.1],\n",
    "               'max_depth': [3, 5, 7],\n",
    "               'subsample': [0.5, 0.7],\n",
    "               'colsample_bytree': [0.5, 0.7],\n",
    "               'n_estimators': [10, 20, 30]}\n",
    "boost_grid = RandomizedSearchCV(XGBClassifier(),\n",
    "                                param_boost, n_jobs=-1)\n",
    "boost_grid.fit(X_train_under, y_train_under)\n",
    "prediction_boost = boost_grid.predict(X_test_under)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_boost = confusion_matrix(y_true=y_test_under,\n",
    "                                  y_pred=prediction_boost)\n",
    "print('Confusion matrix:\\n', conf_mat_boost)\n",
    "print('--' * 25)\n",
    "print('Classification report:\\n', \n",
    "      classification_report(y_test_under, prediction_boost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-Based Fraud Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_df_sampled = fraud_df.sample(int(len(fraud_df) * 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_fp = 2\n",
    "cost_fn = fraud_df_sampled['amt']\n",
    "cost_tp = 2\n",
    "cost_tn = 0\n",
    "cost_mat = np.array([cost_fp * np.ones(fraud_df_sampled.shape[0]),\n",
    "                     cost_fn,\n",
    "                     cost_tp * np.ones(fraud_df_sampled.shape[0]),\n",
    "                     cost_tn * np.ones(fraud_df_sampled.shape[0])]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_log = conf_mat_log[0][1] * cost_fp + conf_mat_boost[1][0] * \\\n",
    "            cost_fn.mean() + conf_mat_log[1][1] * cost_tp\n",
    "cost_dt = conf_mat_dt[0][1] * cost_fp + conf_mat_boost[1][0] * \\\n",
    "          cost_fn.mean() + conf_mat_dt[1][1] * cost_tp\n",
    "cost_rf = conf_mat_rf[0][1] * cost_fp + conf_mat_boost[1][0] * \\\n",
    "          cost_fn.mean() + conf_mat_rf[1][1] * cost_tp\n",
    "cost_boost = conf_mat_boost[0][1] * cost_fp + conf_mat_boost[1][0] * \\\n",
    "             cost_fn.mean() + conf_mat_boost[1][1] * cost_tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Scores for Different ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn==0.22 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import sys\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n",
    "from costcla.metrics import cost_loss, savings_score\n",
    "from costcla.models import BayesMinimumRiskClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, cost_mat_train, cost_mat_test = \\\n",
    "train_test_split(fraud_df_sampled.drop('is_fraud', axis=1),\n",
    "                           fraud_df_sampled.is_fraud, cost_mat,\n",
    "                           test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_models = []\n",
    "saving_models.append(('Log. Reg.', \n",
    "                      LogisticRegression()))\n",
    "saving_models.append(('Dec. Tree', \n",
    "                      DecisionTreeClassifier()))\n",
    "saving_models.append(('Random Forest', \n",
    "                      RandomForestClassifier()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_score_base_all = []\n",
    "\n",
    "for name, save_model in saving_models:\n",
    "    sv_model = save_model\n",
    "    sv_model.fit(X_train, y_train)\n",
    "    y_pred = sv_model.predict(X_test)\n",
    "    saving_score_base = savings_score(y_test, y_pred, cost_mat_test)\n",
    "    saving_score_base_all.append(saving_score_base)\n",
    "    print('The saving score for {} is {:.4f}'. \n",
    "          format(name, saving_score_base))\n",
    "    print('--' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_base_all = []\n",
    "\n",
    "for name, save_model in saving_models:\n",
    "    sv_model = save_model\n",
    "    sv_model.fit(X_train, y_train)\n",
    "    y_pred = sv_model.predict(X_test)\n",
    "    f1_score_base = f1_score(y_test, y_pred, cost_mat_test)\n",
    "    f1_score_base_all.append(f1_score_base)\n",
    "    print('The F1 score for {} is {:.4f}'.\n",
    "          format(name, f1_score_base))\n",
    "    print('--' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-Sensitive Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from costcla.models import CostSensitiveLogisticRegression\n",
    "from costcla.models import CostSensitiveDecisionTreeClassifier\n",
    "from costcla.models import CostSensitiveRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_sen_models = []\n",
    "cost_sen_models.append(('Log. Reg. CS',\n",
    "                        CostSensitiveLogisticRegression()))\n",
    "cost_sen_models.append(('Dec. Tree CS',\n",
    "                        CostSensitiveDecisionTreeClassifier()))\n",
    "cost_sen_models.append(('Random Forest CS',\n",
    "                        CostSensitiveRandomForestClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_cost_all = []\n",
    "\n",
    "for name, cost_model in cost_sen_models:\n",
    "    cs_model = cost_model\n",
    "    cs_model.fit(np.array(X_train), np.array(y_train),\n",
    "                 cost_mat_train)\n",
    "    y_pred = cs_model.predict(np.array(X_test))\n",
    "    saving_score_cost = savings_score(np.array(y_test),\n",
    "                                      np.array(y_pred), cost_mat_test)\n",
    "    saving_cost_all.append(saving_score_cost)\n",
    "    print('The saving score for {} is {:.4f}'.\n",
    "          format(name, saving_score_cost))\n",
    "    print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_cost_all = []\n",
    "\n",
    "for name, cost_model in cost_sen_models:\n",
    "    cs_model = cost_model\n",
    "    cs_model.fit(np.array(X_train), np.array(y_train),\n",
    "                 cost_mat_train)\n",
    "    y_pred = cs_model.predict(np.array(X_test))\n",
    "    f1_score_cost = f1_score(np.array(y_test),\n",
    "                             np.array(y_pred), cost_mat_test)\n",
    "    f1_score_cost_all.append(f1_score_cost)\n",
    "    print('The F1 score for {} is {:.4f}'. format(name,\n",
    "                                                  f1_score_cost))\n",
    "    print('--'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Minimum Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_score_bmr_all = []\n",
    "\n",
    "for name, bmr_model in saving_models:\n",
    "    f = bmr_model.fit(X_train, y_train)\n",
    "    y_prob_test = f.predict_proba(np.array(X_test))\n",
    "    f_bmr = BayesMinimumRiskClassifier()\n",
    "    f_bmr.fit(np.array(y_test), y_prob_test)\n",
    "    y_pred_test = f_bmr.predict(np.array(y_prob_test),\n",
    "                                cost_mat_test)\n",
    "    saving_score_bmr = savings_score(y_test, y_pred_test,\n",
    "                                     cost_mat_test)\n",
    "    saving_score_bmr_all.append(saving_score_bmr)\n",
    "    print('The saving score for {} is {:.4f}'.\\\n",
    "          format(name, saving_score_bmr))\n",
    "    print('--' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_bmr_all = []\n",
    "\n",
    "for name, bmr_model in saving_models:\n",
    "    f = bmr_model.fit(X_train, y_train)\n",
    "    y_prob_test = f.predict_proba(np.array(X_test))\n",
    "    f_bmr = BayesMinimumRiskClassifier()\n",
    "    f_bmr.fit(np.array(y_test), y_prob_test)\n",
    "    y_pred_test = f_bmr.predict(np.array(y_prob_test),\n",
    "                                cost_mat_test)\n",
    "    f1_score_bmr = f1_score(y_test, y_pred_test)\n",
    "    f1_score_bmr_all.append(f1_score_bmr)\n",
    "    print('The F1 score for {} is {:.4f}'.\\\n",
    "          format(name, f1_score_bmr))\n",
    "    print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savings = [saving_score_base_all, saving_cost_all, saving_score_bmr_all]\n",
    "f1 = [f1_score_base_all, f1_score_cost_all, f1_score_bmr_all]\n",
    "saving_scores = pd.concat([pd.Series(x) for x in savings])\n",
    "f1_scores = pd.concat([pd.Series(x) for x in f1])\n",
    "scores = pd.concat([saving_scores, f1_scores], axis=1)\n",
    "scores.columns = ['saving_scores', 'F1_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Log. Reg_base', 'Dec. Tree_base', 'Random Forest_base',\n",
    "               'Log. Reg_cs', 'Dec. Tree_cs', 'Random Forest_cs',\n",
    "              'Log. Reg_bayes', 'Dec. Tree_bayes',\n",
    "               'Random Forest_bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(scores.shape[0]), scores[\"F1_scores\"],\n",
    "         \"--\", label='F1Score')\n",
    "plt.bar(np.arange(scores.shape[0]), scores['saving_scores'],\n",
    "        0.6, label='Savings')\n",
    "_ = np.arange(len(model_names))\n",
    "plt.xticks(_, model_names)\n",
    "plt.legend(loc='best')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standard = StandardScaler()\n",
    "scaled_fraud = standard.fit_transform(X_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_som.som import SOM\n",
    "som = SOM(m=2, n=1, dim=scaled_fraud.shape[1])\n",
    "som.fit(scaled_fraud)\n",
    "predictions_som = som.predict(np.array(scaled_fraud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_som = np.where(predictions_som == 1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification report:\\n', \n",
    "      classification_report(y_under, predictions_som))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 6))\n",
    "x = X_under.iloc[:,0]\n",
    "y = X_under.iloc[:,1]\n",
    "\n",
    "ax[0].scatter(x, y, alpha=0.1, cmap='Greys', c=y_under)\n",
    "ax[0].title.set_text('Actual Classes')\n",
    "ax[1].scatter(x, y, alpha=0.1, cmap='Greys', c=predictions_som) \n",
    "ax[1].title.set_text('SOM Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_df[['amt','city_pop','hour']] = StandardScaler().\\\n",
    "fit_transform(fraud_df[['amt','city_pop','hour']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(fraud_df,\n",
    "                                   test_size=0.2, random_state=123)\n",
    "X_train[X_train['is_fraud'] == 0]\n",
    "X_train = X_train.drop(['is_fraud'], axis=1).values\n",
    "y_test = X_test['is_fraud']\n",
    "X_test = X_test.drop(['is_fraud'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = keras.Sequential()\n",
    "autoencoder.add(Dense(X_train_under.shape[1], activation='tanh',\n",
    "                      activity_regularizer=regularizers.l1(10e-5),\n",
    "                      input_dim= X_train_under.shape[1]))\n",
    "#encoder\n",
    "autoencoder.add(Dense(64, activation='tanh'))\n",
    "autoencoder.add(Dense(32, activation='relu'))\n",
    "#decoder\n",
    "autoencoder.add(Dense(32, activation='elu'))\n",
    "autoencoder.add(Dense(64,activation='tanh'))\n",
    "autoencoder.add(Dense(X_train_under.shape[1], activation='elu'))\n",
    "autoencoder.compile(loss='mse',\n",
    "                    optimizer='adam')\n",
    "autoencoder.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(X_train, X_train,\n",
    "                          shuffle=True,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size,\n",
    "                          validation_data=(X_test, X_test),\n",
    "                          verbose=0).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_pred = autoencoder.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - autoencoder_pred, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': y_test})\n",
    "mse = np.mean(np.power(X_test - autoencoder_pred, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': y_test})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
