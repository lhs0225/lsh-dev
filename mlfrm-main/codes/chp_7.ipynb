{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "pd.set_option('use_inf_as_na', True)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe8daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_data = pd.read_csv('datasets/bid_ask.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ef45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d7e13",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "rolling_five = []\n",
    "\n",
    "for j in liq_data.TICKER.unique():\n",
    "    for i in range(len(liq_data[liq_data.TICKER == j])):\n",
    "        rolling_five.append(liq_data[i:i+5].agg({'BIDLO': 'min',\n",
    "                                                'ASKHI': 'max',\n",
    "                                                 'VOL': 'sum',\n",
    "                                                 'SHROUT': 'mean',\n",
    "                                                 'PRC': 'mean'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f642423",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_five_df = pd.DataFrame(rolling_five)\n",
    "rolling_five_df.columns = ['bidlo_min', 'askhi_max', 'vol_sum',\n",
    "                           'shrout_mean', 'prc_mean']\n",
    "liq_vol_all = pd.concat([liq_data,rolling_five_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11274b7",
   "metadata": {},
   "source": [
    "## Volume Based Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaec6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_ratio = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        liq_ratio.append((liq_vol_all['PRC'][i+1:i+6] * \n",
    "                          liq_vol_all['VOL'][i+1:i+6]).sum()/\n",
    "                         (np.abs(liq_vol_all['PRC'][i+1:i+6].mean() - \n",
    "                                 liq_vol_all['PRC'][i:i+5].mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbe3e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lhh = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        Lhh.append((liq_vol_all['PRC'][i:i+5].max() - \n",
    "                    liq_vol_all['PRC'][i:i+5].min()) /  \n",
    "                   liq_vol_all['PRC'][i:i+5].min() /  \n",
    "                   (liq_vol_all['VOL'][i:i+5].sum() / \n",
    "                    liq_vol_all['SHROUT'][i:i+5].mean() * \n",
    "                    liq_vol_all['PRC'][i:i+5].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_ratio = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        turnover_ratio.append((1/liq_vol_all['VOL'].count()) * \n",
    "                              (np.sum(liq_vol_all['VOL'][i:i+1]) / \n",
    "                               np.sum(liq_vol_all['SHROUT'][i:i+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2edf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all['liq_ratio'] = pd.DataFrame(liq_ratio)\n",
    "liq_vol_all['Lhh'] = pd.DataFrame(Lhh)\n",
    "liq_vol_all['turnover_ratio'] = pd.DataFrame(turnover_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e135f29f",
   "metadata": {},
   "source": [
    "## Transaction Cost Based Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cccab2",
   "metadata": {},
   "source": [
    "### Bid-Ask Spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc91ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all['mid_price'] = (liq_vol_all.ASKHI + liq_vol_all.BIDLO) / 2\n",
    "liq_vol_all['percent_quoted_ba'] = (liq_vol_all.ASKHI - \n",
    "                                    liq_vol_all.BIDLO) / \\\n",
    "                                    liq_vol_all.mid_price\n",
    "liq_vol_all['percent_effective_ba'] = 2 * abs((liq_vol_all.PRC - \n",
    "                                               liq_vol_all.mid_price)) / \\\n",
    "                                               liq_vol_all.mid_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ca49a",
   "metadata": {},
   "source": [
    "### Roll's Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e37d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all['price_diff'] = liq_vol_all.groupby('TICKER')['PRC']\\\n",
    "                            .apply(lambda x:x.diff())\n",
    "liq_vol_all.dropna(inplace=True)\n",
    "roll = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "     for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        roll_cov = np.cov(liq_vol_all['price_diff'][i:i+5], \n",
    "                          liq_vol_all['price_diff'][i+1:i+6])\n",
    "        if roll_cov[0,1] < 0:\n",
    "            roll.append(2 * np.sqrt(-roll_cov[0, 1]))\n",
    "        else:\n",
    "             roll.append(2 * np.sqrt(np.abs(roll_cov[0, 1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472c49c",
   "metadata": {},
   "source": [
    "### Corwin and Schultz (2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec507fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        gamma.append((max(liq_vol_all['ASKHI'].iloc[i+1], \n",
    "                          liq_vol_all['ASKHI'].iloc[i]) - \n",
    "                      min(liq_vol_all['BIDLO'].iloc[i+1], \n",
    "                          liq_vol_all['BIDLO'].iloc[i])) ** 2)\n",
    "        gamma_array = np.array(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab72f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        beta.append((liq_vol_all['ASKHI'].iloc[i+1] - \n",
    "                     liq_vol_all['BIDLO'].iloc[i+1]) ** 2 + \n",
    "                    (liq_vol_all['ASKHI'].iloc[i] - \n",
    "                     liq_vol_all['BIDLO'].iloc[i]) ** 2)\n",
    "        beta_array = np.array(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6da937",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = ((np.sqrt(2 * beta_array) - np.sqrt(beta_array)) / \n",
    "       (3 - (2 * np.sqrt(2)))) - np.sqrt(gamma_array / \n",
    "                                         (3 - (2 * np.sqrt(2))))\n",
    "CS_spread = (2 * np.exp(alpha - 1)) / (1 + np.exp(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all = liq_vol_all.reset_index()\n",
    "liq_vol_all['roll'] = pd.DataFrame(roll)\n",
    "liq_vol_all['CS_spread'] = pd.DataFrame(CS_spread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ee3e6",
   "metadata": {},
   "source": [
    "## Price Based Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c9209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvol = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        dvol.append((liq_vol_all['PRC'][i:i+5] *\n",
    "                     liq_vol_all['VOL'][i:i+5]).sum())\n",
    "liq_vol_all['dvol'] = pd.DataFrame(dvol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35252634",
   "metadata": {},
   "outputs": [],
   "source": [
    "amihud = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        amihud.append((1 / liq_vol_all['RET'].count()) * \n",
    "                      (np.sum(np.abs(liq_vol_all['RET'][i:i+1])) / \n",
    "                              np.sum(liq_vol_all['dvol'][i:i+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06803a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "florackis = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        florackis.append((1 / liq_vol_all['RET'].count()) * \n",
    "                         (np.sum(np.abs(liq_vol_all['RET'][i:i+1]) / \n",
    "                                 liq_vol_all['turnover_ratio'][i:i+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4540974",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all['vol_diff_pct'] = liq_vol_all.groupby('TICKER')['VOL']\\\n",
    "                              .apply(lambda x: x.diff()).pct_change()\n",
    "liq_vol_all['price_diff_pct'] = liq_vol_all.groupby('TICKER')['PRC']\\\n",
    "                              .apply(lambda x: x.diff()).pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46df604",
   "metadata": {},
   "outputs": [],
   "source": [
    "cet = []\n",
    "\n",
    "for j in liq_vol_all.TICKER.unique():\n",
    "    for i in range(len(liq_vol_all[liq_vol_all.TICKER == j])):\n",
    "        cet.append(np.sum(liq_vol_all['vol_diff_pct'][i:i+1])/\n",
    "                   np.sum(liq_vol_all['price_diff_pct'][i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbfa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all['amihud'] = pd.DataFrame(amihud)\n",
    "liq_vol_all['florackis'] = pd.DataFrame(florackis)\n",
    "liq_vol_all['cet'] = pd.DataFrame(cet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33015fc",
   "metadata": {},
   "source": [
    "## Market Impact Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4255c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_vol_all['VOL_pct_change'] = liq_vol_all.groupby('TICKER')['VOL']\\\n",
    "                                .apply(lambda x: x.pct_change())\n",
    "liq_vol_all.dropna(subset=['VOL_pct_change'], inplace=True)\n",
    "liq_vol_all = liq_vol_all.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61843be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsys_resid = []\n",
    "\n",
    "for i in liq_vol_all.TICKER.unique():\n",
    "    X1 = liq_vol_all[liq_vol_all['TICKER'] == i]['vwretx']\n",
    "    y = liq_vol_all[liq_vol_all['TICKER'] == i]['RET']\n",
    "    ols = sm.OLS(y, X1).fit()\n",
    "    unsys_resid.append(ols.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d8f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_impact = {}\n",
    "\n",
    "for i, j in zip(liq_vol_all.TICKER.unique(), \n",
    "                range(len(liq_vol_all['TICKER'].unique()))):\n",
    "    X2 = liq_vol_all[liq_vol_all['TICKER'] == i]['VOL_pct_change']\n",
    "    ols = sm.OLS(unsys_resid[j] ** 2, X2).fit()\n",
    "    print('***' * 30)\n",
    "    print(f'OLS Result for {i}')\n",
    "    print(ols.summary())\n",
    "    market_impact[j] = ols.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa0827",
   "metadata": {},
   "outputs": [],
   "source": [
    "append1 = market_impact[0].append(market_impact[1])\n",
    "liq_vol_all['market_impact'] = append1.append(market_impact[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['vol_diff_pct', 'price_diff_pct', 'price_diff',\n",
    "        'VOL_pct_change', 'dvol', 'mid_price']\n",
    "liq_measures_all = liq_vol_all.drop(liq_vol_all[cols], axis=1)\\\n",
    "                   .iloc[:, -11:]\n",
    "liq_measures_all.dropna(inplace=True)\n",
    "liq_measures_all.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e951cc",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd3c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f5b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_measures_all2 = liq_measures_all.dropna()\n",
    "scaled_liq = StandardScaler().fit_transform(liq_measures_all2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52393f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(alpha=0.5, bins=50,  stacked=True)\n",
    "plt.hist(liq_measures_all.loc[:, 'percent_quoted_ba'],\n",
    "         **kwargs, label='TC-based')\n",
    "plt.hist(liq_measures_all.loc[:, 'turnover_ratio'],\n",
    "         **kwargs, label='Volume-based')\n",
    "plt.hist(liq_measures_all.loc[:, 'market_impact'],\n",
    "         **kwargs, label='Market-based')\n",
    "plt.title('Multimodality of the Liquidity Measures')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = np.arange(1, 10)\n",
    "clusters = [GaussianMixture(n, covariance_type='spherical',\n",
    "                            random_state=0).fit(scaled_liq)\n",
    "          for n in n_components]\n",
    "plt.plot(n_components, [m.bic(scaled_liq) for m in clusters])\n",
    "plt.title('Optimum Number of Components')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('BIC values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee26c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_state(data, nstates):\n",
    "    gmm = GaussianMixture(n_components=nstates,\n",
    "                          covariance_type='spherical',\n",
    "                          init_params='kmeans')\n",
    "    gmm_fit = gmm.fit(scaled_liq)\n",
    "    labels = gmm_fit.predict(scaled_liq)\n",
    "    state_probs = gmm.predict_proba(scaled_liq)\n",
    "    state_probs_df = pd.DataFrame(state_probs, \n",
    "                                  columns=['state-1','state-2','state-3'])\n",
    "    state_prob_means = [state_probs_df.iloc[:, i].mean() \n",
    "                        for i in range(len(state_probs_df.columns))]\n",
    "    if np.max(state_prob_means) == state_prob_means[0]:\n",
    "        print('State-1 is likely to occur with a probability of {:4f}'\n",
    "              .format(state_prob_means[0]))\n",
    "    elif np.max(state_prob_means) == state_prob_means[1]:\n",
    "        print('State-2 is likely to occur with a probability of {:4f}'\n",
    "              .format(state_prob_means[1]))\n",
    "    else:\n",
    "        print('State-3 is likely to occur with a probability of {:4f}'\n",
    "              .format(state_prob_means[2]))\n",
    "    return state_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41148b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_probs = cluster_state(scaled_liq, 3)\n",
    "print(f'State probabilities are {state_probs.mean(axis=0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da06dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3740fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=11)\n",
    "components = pca.fit_transform(scaled_liq)\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('% of Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8588a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_pca(data, nstate):\n",
    "    pca = PCA(n_components=3)\n",
    "    components = pca.fit_transform(data)\n",
    "    mxtd = GaussianMixture(n_components=nstate,\n",
    "                           covariance_type='spherical')\n",
    "    gmm = mxtd.fit(components)\n",
    "    labels = gmm.predict(components)\n",
    "    state_probs = gmm.predict_proba(components)\n",
    "    return state_probs,pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef610512",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_probs, pca = gmm_pca(scaled_liq, 3)\n",
    "print(f'State probabilities are {state_probs.mean(axis=0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wpc():\n",
    "    state_probs_df = pd.DataFrame(state_probs,\n",
    "                                  columns=['state-1', 'state-2',\n",
    "                                           'state-3'])\n",
    "    state_prob_means = [state_probs_df.iloc[:, i].mean() \n",
    "                        for i in range(len(state_probs_df.columns))]\n",
    "    if np.max(state_prob_means) == state_prob_means[0]:\n",
    "        print('State-1 is likely to occur with a probability of {:4f}'\n",
    "              .format(state_prob_means[0]))\n",
    "    elif np.max(state_prob_means) == state_prob_means[1]:\n",
    "        print('State-2 is likely to occur with a probability of {:4f}'\n",
    "              .format(state_prob_means[1]))\n",
    "    else:\n",
    "        print('State-3 is likely to occur with a probability of {:4f}'\n",
    "              .format(state_prob_means[2]))\n",
    "wpc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f538d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "loading_matrix = pd.DataFrame(loadings, \n",
    "                              columns=['PC1', 'PC2', 'PC3'],\n",
    "                              index=liq_measures_all.columns)\n",
    "loading_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213db006",
   "metadata": {},
   "source": [
    "## GMCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d5149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copulae.mixtures.gmc.gmc import GaussianMixtureCopula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, dim = scaled_liq.shape\n",
    "gmcm = GaussianMixtureCopula(n_clusters=3, ndim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmcm_fit = gmcm.fit(scaled_liq, method='kmeans',\n",
    "                    criteria='GMCM', eps=0.0001)\n",
    "state_prob = gmcm_fit.params.prob\n",
    "print(f'The state {np.argmax(state_prob) + 1} is likely to occur')\n",
    "print(f'State probabilities based on GMCM are {state_prob}')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
