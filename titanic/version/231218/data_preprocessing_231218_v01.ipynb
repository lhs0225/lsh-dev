{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get started! ‚ö°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT THE NECESSARY PYTHON LIBRARIES\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ ÏùΩÏñ¥Ïò§Í∏∞\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ìó§Îìú ÌôïÏù∏\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12) (418, 11)\n"
     ]
    }
   ],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞Ïùò Ïª¨Îüº Ïàò ÌôïÏù∏\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Ïª¨ÎüºÎ≥Ñ ÌÉÄÏûÖÍ≥º NullÍ∞í ÌôïÏù∏\n",
    "print(df_train.info())\n",
    "print()\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis üìäü§î"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌîºÏ≤òÎ≥ÑÎ°ú ÌïôÏäµÎç∞Ïù¥ÌÑ∞, ÌÖåÏä§Ìä∏Îç∞Ïù¥ÌÑ∞, ÏñëÏ™ΩÏùÑ Ìï©Ïπú Ï¥ù ÏÉùÏ°¥ÏûêÏùò ÎπÑÏú®ÏùÑ ÏãúÍ∞ÅÌôîÌï¥Ï£ºÎäî Ìï®Ïàò\n",
    "# plt, seaborn importÌïòÍ≥†, eda_bar_plots(Ïª¨ÎüºÎ™Ö) ÏûÖÎ†•ÌïòÏãúÎ©¥ Îê©ÎãàÎã§.\n",
    "def eda_bar_plots(feature: str, target: str = 'Survived') -> None:\n",
    "    \"\"\"\n",
    "    The given 'feature' is expected to be a categorical feature.\n",
    "    Avoid calling this function with 'feature' == 'Age' or 'Fare'\n",
    "    \n",
    "    This function crates 3 bar plots to perform a visual\n",
    "    Data Exploration analysis of the given 'feature'.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "    \n",
    "    # (1) the distribution of 'feature' in the Training data\n",
    "    df1 = df_train[feature].value_counts(normalize=True) \n",
    "    df1 = df1.sort_index().reset_index()\n",
    "    # Now df1 has the columns: feature and 'proportion'\n",
    "    sns.barplot(data=df1, x=feature, y='proportion', ax=ax1)\n",
    "    # Set the title, the xlabel, and the ylabel.\n",
    "    ax1.set(\n",
    "        xlabel=feature, \n",
    "        ylabel='% of each category', \n",
    "        title=feature + ': % value counts [Training Data]'\n",
    "    )\n",
    "    # Plot a horizontal line at the proportion of a balanced\n",
    "    # distribution of the categories in 'feature'\n",
    "    ax1.axhline(\n",
    "        y=1/len(df1), color='green', alpha=0.4, linestyle='--'\n",
    "    )\n",
    "    \n",
    "    # (2) the distribution of 'feature' in the Test data\n",
    "    df2 = df_test[feature].value_counts(normalize=True) \n",
    "    df2 = df2.sort_index().reset_index()\n",
    "    # Now df2 has the columns: feature and 'proportion'\n",
    "    sns.barplot(data=df2, x=feature, y='proportion', ax=ax2)\n",
    "    # Set the title, the xlabel, and the ylabel.\n",
    "    ax2.set(\n",
    "        xlabel=feature, \n",
    "        ylabel='% of each category', \n",
    "        title=feature + ': % value counts [Test Data]'\n",
    "    )\n",
    "    # Plot a horizontal line at the proportion of a balanced\n",
    "    # distribution of the categories in 'feature'\n",
    "    ax2.axhline(\n",
    "        y=1/len(df2), color='green', alpha=0.4, linestyle='--'\n",
    "    )\n",
    "    \n",
    "    # (3) the relationship between the 'target' and the \n",
    "    # categories of 'feature' in the training data\n",
    "    df3 = df_train.groupby(feature, as_index=False).agg(\n",
    "        {target: 'mean'}\n",
    "    ).sort_values(by=feature)\n",
    "    sns.barplot(x=feature, y=target, data=df3, ax=ax3)\n",
    "    ax3.set(\n",
    "        xlabel=feature,\n",
    "        ylabel=f'% {target}', \n",
    "        title=f\"{feature}: prob of '{target}'\"\n",
    "    )\n",
    "    # Plot a horizontal line at the baseline prediction\n",
    "    # probability: two classes -> prob=0.5\n",
    "    ax3.axhline(\n",
    "        y=0.5, color='green', alpha=0.4, linestyle='--'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing ‚öôÔ∏èüßπ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'PassengerId' Ïª¨Îüº ÎìúÎûç (ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ X)\n",
    "# Ï†úÏ∂úÌï† ÎïåÎäî Ïª¨Îüº Îã§Ïãú Ï∂îÍ∞ÄÌï¥Ï§òÏïº Ìï©ÎãàÎã§.\n",
    "def drop_PassengerId(df_train):\n",
    "    df_train = df_train.drop(columns=['PassengerId'])\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Name' Ïª¨ÎüºÏóêÏÑú 'honorific_title' Ïª¨Îüº ÏÉùÏÑ±ÌïòÍ∏∞\n",
    "# ÏùòÎØ∏ÏûàÎäî Ìò∏Ïπ≠(Mr, Mrs, Miss, Master)ÏùÑ Ï∂îÏ∂úÌïòÎäî Í≥ºÏ†ïÏûÖÎãàÎã§.\n",
    "\n",
    "# Ïòà : \"Braund, Mr. Owen Harris\"ÏóêÏÑú 'Mr' Ï∂îÏ∂ú\n",
    "def get_honorific_name(df_train, df_test):\n",
    "    # '.'(ÎßàÏπ®Ìëú) Í∏∞Ï§ÄÏúºÎ°ú Ïù¥Î¶ÑÏùÑ ÏûêÎ•¥Í≥†, ','(ÏΩ§Îßà) Ï†úÍ±∞\n",
    "    honorific_title_train = df_train['Name'].map(\n",
    "        lambda n: n.split('.')[0].split(', ')[-1]\n",
    "    )\n",
    "    honorific_title_test = df_test['Name'].map(\n",
    "        lambda n: n.split('.')[0].split(', ')[-1]\n",
    "    )\n",
    "\n",
    "    # ÏÉà ÌîºÏ≥êÎ°ú ÏÇ¨Ïö©Ìï† Ïª¨Îüº 'honorific_title' ÏÉùÏÑ±\n",
    "    top4_titles = ('Mr', 'Mrs', 'Miss', 'Master')\n",
    "\n",
    "    df_train['honorific_title'] = honorific_title_train.map(\n",
    "        lambda h: h if h in top4_titles else np.nan\n",
    "    )\n",
    "    df_test['honorific_title'] = honorific_title_test.map(\n",
    "        lambda h: h if h in top4_titles else np.nan\n",
    "    )\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Name' Ïª¨ÎüºÏóêÏÑú 'honorific_title' Ïª¨Îüº ÏÉùÏÑ±ÌïòÍ∏∞\n",
    "# ÏùòÎØ∏ÏûàÎäî Ìò∏Ïπ≠(Mr, Mrs, Miss, Master)ÏùÑ Ï∂îÏ∂úÌïòÎäî Í≥ºÏ†ïÏûÖÎãàÎã§.\n",
    "\n",
    "# 'honorific_title' ÏÉùÏÑ±ÌïòÎäî Ìï®Ïàò\n",
    "def get_honorific_title(name):\n",
    "    top4_titles = ('Mr', 'Mrs', 'Miss', 'Master')\n",
    "\n",
    "    # top4 Ìò∏Ïπ≠ÏúºÎ°ú Î∞îÍøîÏ§Ñ ÏÜåÏàò Ïó¨ÏÑ± Ìò∏Ïπ≠\n",
    "    female_titles_to_Mrs = ('Mme', 'the Countess', 'Dona', 'Lady')\n",
    "    female_titles_to_Miss = ('Mlle', 'Ms')\n",
    "\n",
    "    # top4 Ìò∏Ïπ≠ÏúºÎ°ú Î∞îÍøîÏ§Ñ ÏÜåÏàò ÎÇ®ÏÑ± Ìò∏Ïπ≠\n",
    "    male_titles_to_Mr = ('Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer', 'Rev')\n",
    "\n",
    "    # Ïòà : \"Braund, Mr. Owen Harris\"ÏóêÏÑú 'Mr' Ï∂îÏ∂ú\n",
    "    # '.'(ÎßàÏπ®Ìëú) Í∏∞Ï§ÄÏúºÎ°ú Ïù¥Î¶ÑÏùÑ ÏûêÎ•¥Í≥†, ','(ÏΩ§Îßà) Ï†úÍ±∞\n",
    "    honorific_title = name.split('.')[0].split(', ')[-1]\n",
    "\n",
    "    # Ìò∏Ïπ≠Ïóê Îî∞Îùº Î≥ÄÌôòÌï¥ÏÑú Î¶¨ÌÑ¥\n",
    "    if honorific_title in top4_titles:\n",
    "        return honorific_title\n",
    "    elif honorific_title in female_titles_to_Mrs:\n",
    "        return 'Mrs'\n",
    "    elif honorific_title in female_titles_to_Miss:\n",
    "        return 'Miss'\n",
    "    elif honorific_title in male_titles_to_Mr:\n",
    "        return 'Mr'\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏÉà ÌîºÏ≥êÎ°ú ÏÇ¨Ïö©Ìï† Ïª¨Îüº 'honorific_title' ÏÉùÏÑ±\n",
    "def make_honorific_title(df_train, df_test):\n",
    "    df_train['honorific_title'] = df_train['Name'].map(get_honorific_title)\n",
    "    df_test['honorific_title'] = df_test['Name'].map(get_honorific_title)\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏõêÎûò Ïª¨Îüº 'Name'Î•º ÎìúÎûç\n",
    "def drop_Name(df_train, df_test):\n",
    "    df_train = df_train.drop(columns=['Name'])\n",
    "    df_test = df_test.drop(columns=['Name'])\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'SibSp' Î†àÏù¥Î∏î Ïù∏ÏΩîÎî©\n",
    "def encoding_SibSp(df_train, df_test):\n",
    "    df_train['SibSp'] = df_train['SibSp'].map(\n",
    "        lambda s: str(s) if s < 2 else '>=2'\n",
    "    )\n",
    "    df_test['SibSp'] = df_test['SibSp'].map(\n",
    "        lambda s: str(s) if s < 2 else '>=2'\n",
    "    )\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Parch' Î†àÏù¥Î∏î Ïù∏ÏΩîÎî©\n",
    "def encoding_Parch(df_train, df_test):\n",
    "    df_train['Parch'] = df_train['Parch'].map(\n",
    "        lambda p: '0' if p == 0 else '>0'\n",
    "    )\n",
    "    df_test['Parch'] = df_test['Parch'].map(\n",
    "        lambda p: '0' if p == 0 else '>0'\n",
    "    )\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏÉà Ïª¨Îüº 'Family' ÏÉùÏÑ± ÌõÑ Î†àÏù¥Î∏î Ïù∏ÏΩîÎî©\n",
    "def make_Family_column(df_train, df_test):\n",
    "    # 'Famliy' Ïª¨Îüº Í≥ÑÏÇ∞Ìï¥ÏÑú ÏÉùÏÑ±\n",
    "    df_train['Family'] = df_train['SibSp'].astype(int) + df_train['Parch'].astype(int) + 1\n",
    "    df_test['Family'] = df_test['SibSp'].astype(int) + df_test['Parch'].astype(int) + 1\n",
    "    \n",
    "    # 'Famliy' Ïª¨Îüº Î†àÏù¥Î∏î Ïù∏ÏΩîÎî©\n",
    "    df_train['Family'] = df_train['Family'].map(\n",
    "        lambda f : str(f) if f < 3 else '>=3'\n",
    "    )\n",
    "\n",
    "    df_test['Family'] = df_test['Family'].map(\n",
    "        lambda f : str(f) if f < 3 else '>=3'\n",
    "    )\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'SibSp' Ïª¨Îüº ÎìúÎûç\n",
    "def drop_SibSp(df_train, df_test):\n",
    "    df_train = df_train.drop(columns=['SibSp'])\n",
    "    df_test = df_test.drop(columns=['SibSp'])\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Parch' Ïª¨Îüº ÎìúÎûç\n",
    "def drop_Parch(df_train, df_test):\n",
    "    df_train = df_train.drop(columns=['Parch'])\n",
    "    df_test = df_test.drop(columns=['Parch'])\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Cabin' Ïª¨Îüº ÎìúÎûç (Í≤∞Ï∏°ÏπòÍ∞Ä ÎÑàÎ¨¥ ÎßéÏùå)\n",
    "def drop_Cabin(df_train, df_test):\n",
    "    df_train = df_train.drop(columns=['Cabin'])\n",
    "    df_test = df_test.drop(columns=['Cabin'])\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Ticket' Ïª¨Îüº ÎìúÎûç (ÏùòÎØ∏Î•º Ï∞æÏùÑÏàò ÏóÜÏùå)\n",
    "def drop_Ticket(df_train, df_test):\n",
    "    df_train = df_train.drop(columns=['Ticket'])\n",
    "    df_test = df_test.drop(columns=['Ticket'])\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Age' Í≤∞Ï∏°Ïπò Ï±ÑÏö∞Îäî ÌÅ¥ÎûòÏä§\n",
    "class AgeImputer(\n",
    "    SimpleImputer, TransformerMixin\n",
    "):\n",
    "    \"\"\"\n",
    "    Age Imputer from 'honorific_title' column.\n",
    "\n",
    "    There are four honorific titles: Mr, Mrs, Miss, Master.\n",
    "    We proved that these groups have statistically different\n",
    "    mean Ages (Independent T-tests).\n",
    "\n",
    "    Imputation strategy:\n",
    "        - fit:  compute the mean Age for each honorifit title\n",
    "            Compute the mean Age for those who do not have title\n",
    "        - transform:  if Age is missing for a passenger, if it has\n",
    "            honorific title, the mean Age for that honorific title\n",
    "            will be assigned. Else, the mean age for those who do\n",
    "            not have title will be assigned.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Initialize an AgeImputer instance\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize the parent Sklearn classes\n",
    "        super().__init__()\n",
    "        # Define the mappig {title_: mean Age for title_}\n",
    "        self.title2age = {}\n",
    "        # Define the mean age of those people with no title\n",
    "        self.no_title_mean_age = None\n",
    "        self.is_fitted = False\n",
    "\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        \"\"\"\n",
    "        Fits the 'title2age' and 'honorific_title' using 'X'.\n",
    "\n",
    "        'X' is assumed to be Training Data (not Test Data!)\n",
    "        'X' is assumed to be a non-empty data frame with\n",
    "            (at least) the columns 'Age' and 'honorific_title'\n",
    "        \"\"\"\n",
    "\n",
    "        df_groupby = df_train.groupby(\n",
    "            by='honorific_title'\n",
    "        ).agg({'Age': 'mean'})\n",
    "        self.title2age = df_groupby.to_dict()['Age']\n",
    "\n",
    "        if X['honorific_title'].isna().sum() == 0:\n",
    "            self.no_title_mean_age = X['Age'].mean()\n",
    "        else:\n",
    "            self.no_title_mean_age = X.loc[\n",
    "                X['honorific_title'].isna(), 'Age'\n",
    "            ].mean()\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X: pd.DataFrame, y=None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform 'X' by imputing the missing values of 'Age'\n",
    "\n",
    "        'X' is assumed to be Training Data (not Test Data!)\n",
    "        'X' is assumed to be a non-empty data frame with\n",
    "            (at least) the columns 'Age' and 'honorific_title'\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.is_fitted:\n",
    "            raise Exception(\"Call the 'fit' method first\")\n",
    "\n",
    "        X_out = X.copy(deep=True)\n",
    "        missing_age_idx = X.loc[X['Age'].isna(), :].index\n",
    "        age_col_idx = np.where(X.columns == 'Age')[0][0]\n",
    "\n",
    "        for idx in missing_age_idx:\n",
    "\n",
    "            # get the honorific_title of the 'idx' row\n",
    "            title = X.loc[idx,'honorific_title']\n",
    "\n",
    "            if title in self.title2age:\n",
    "                X_out.loc[idx, 'Age'] = self.title2age[title]\n",
    "            else:\n",
    "                X_out.loc[idx, 'Age'] = self.no_title_mean_age\n",
    "\n",
    "        return X_out['Age'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three imputers : Í≤∞Ï∏°Ïπò Ï±ÑÏö∞Îäî Ìï®ÏàòÎ•º imputerÎùºÍ≥† Ìï©ÎãàÎã§.\n",
    "age_imputer = AgeImputer().set_output(transform='pandas')\n",
    "\n",
    "fare_imputer = SimpleImputer(\n",
    "    strategy='median'\n",
    ").set_output(transform='pandas')\n",
    "\n",
    "embarked_imputer = SimpleImputer(\n",
    "    strategy='most_frequent'\n",
    ").set_output(transform='pandas')\n",
    "\n",
    "\n",
    "# Create a general imputer (for all the variables)\n",
    "imputer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('age_imp', age_imputer, ['Age', 'honorific_title']),\n",
    "        ('fare_imp', fare_imputer, ['Fare']),\n",
    "        ('embarked_imp', embarked_imputer, ['Embarked'])\n",
    "    ],\n",
    "    remainder='passthrough', # ÎÇòÎ®∏ÏßÄÎäî ÎÜîÎëîÎã§.\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'honorific_title' ÌïúÏ†ï ÏõêÌï´ Ïù∏ÏΩîÎî©(ÎÇòÏù¥ Í≤∞Ï∏°Ïπò Ï±ÑÏö∞Îäî Îç∞ ÌïÑÏöî)\n",
    "def make_honorific_title_dummy(df_train, df_test):\n",
    "    df_train['dummy_honorific_title'] = df_train['honorific_title']\n",
    "    df_train = pd.get_dummies(\n",
    "          data=df_train\n",
    "        , columns=['dummy_honorific_title']\n",
    "        , prefix=''\n",
    "        , prefix_sep=''\n",
    "        , dummy_na=False  # Null Ïª¨ÎüºÏùÄ Î≥µÏÇ¨ÌïòÏßÄ ÏïäÎäîÎã§.\n",
    "        , drop_first=False  # Top4 honorific titles ÌñâÏùÄ Ï†ÑÎ∂Ä Î≥µÏÇ¨\n",
    "        , dtype=int\n",
    "    )\n",
    "    \n",
    "    df_test['dummy_honorific_title'] = df_test['honorific_title']\n",
    "    df_test = pd.get_dummies(\n",
    "          data=df_test\n",
    "        , columns=['dummy_honorific_title']\n",
    "        , prefix=''\n",
    "        , prefix_sep=''\n",
    "        , dummy_na=False  # Null Ïª¨ÎüºÏùÄ Î≥µÏÇ¨ÌïòÏßÄ ÏïäÎäîÎã§.\n",
    "        , drop_first=False  # Top4 honorific titles ÌñâÏùÄ Ï†ÑÎ∂Ä Î≥µÏÇ¨\n",
    "        , dtype=int\n",
    "    )\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏõêÌï´ Ïù∏ÏΩîÎî©\n",
    "def one_hot_encoder(df_train, df_test):\n",
    "  df_train = pd.get_dummies(\n",
    "        data=df_train\n",
    "      , dummy_na=False\n",
    "      , drop_first=False\n",
    "      , dtype=int\n",
    "  ).drop(columns='honorific_title')\n",
    "\n",
    "  df_test = pd.get_dummies(\n",
    "        data=df_test\n",
    "      , dummy_na=False\n",
    "      , drop_first=False\n",
    "      , dtype=int\n",
    "  ).drop(columns='honorific_title')\n",
    "  \n",
    "  return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ïª¨Îüº ÏÉùÏÑ± Î∞è ÎìúÎûçÌïòÎäî Ìï®Ïàò Î™®Ïùå\n",
    "def make_drop_columns(df_train, df_test):\n",
    "    # Î∞îÎ°ú ÎìúÎûçÌïòÎäî Ïª¨ÎüºÎì§ ÎìúÎûç\n",
    "    df_train = drop_PassengerId(df_train)\n",
    "    df_train, df_test = drop_Cabin(df_train, df_test)\n",
    "    df_train, df_test = drop_Ticket(df_train, df_test)\n",
    "    \n",
    "    # Ï†ÑÏ≤òÎ¶¨ ÌõÑ Ïù∏ÏΩîÎî©ÌïòÎäî Ïª¨Îüº\n",
    "    df_train, df_test = make_honorific_title(df_train, df_test)\n",
    "    df_train, df_test = drop_Name(df_train, df_test)\n",
    "    \n",
    "    # 'Family' Ïª¨Îüº ÎßåÎì§Í≥† ÌïÑÏöîÏóÜÎäî Ïª¨Îüº ÎìúÎûç\n",
    "    df_train, df_test = make_Family_column(df_train, df_test)\n",
    "    df_train, df_test = drop_SibSp(df_train, df_test)\n",
    "    df_train, df_test = drop_Parch(df_train, df_test)\n",
    "    \n",
    "    # honorific_titleÏùò ÎçîÎØ∏ Ïª¨Îüº ÏÉùÏÑ±\n",
    "    df_train, df_test = make_honorific_title_dummy(df_train, df_test)\n",
    "       \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ïª¨Îüº ÏÉùÏÑ±/ÎìúÎûç Ìï®Ïàò Ïã§Ìñâ\n",
    "df_train, df_test = make_drop_columns(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í≤∞Ï∏°Ïπò Ï±ÑÏö∞Í∏∞\n",
    "df_train = pd.DataFrame(\n",
    "      imputer.fit_transform(df_train)\n",
    "    , columns=df_train.columns\n",
    ")\n",
    "\n",
    "df_test = pd.DataFrame(\n",
    "      imputer.fit_transform(df_test)\n",
    "    , columns=df_test.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏõêÌï´ Ïù∏ÏΩîÎî©\n",
    "df_train, df_test = one_hot_encoder(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Master</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Family_1</th>\n",
       "      <th>Family_2</th>\n",
       "      <th>Family_&gt;=3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age     Fare  Master  Miss  Mr  Mrs  Sex_female  \\\n",
       "0         0       3  22.0   7.2500       0     0   1    0           0   \n",
       "1         1       1  38.0  71.2833       0     0   0    1           1   \n",
       "2         1       3  26.0   7.9250       0     1   0    0           1   \n",
       "3         1       1  35.0  53.1000       0     0   0    1           1   \n",
       "4         0       3  35.0   8.0500       0     0   1    0           0   \n",
       "\n",
       "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  Family_1  Family_2  \\\n",
       "0         1           0           0           1         0         1   \n",
       "1         0           1           0           0         0         1   \n",
       "2         0           0           0           1         1         0   \n",
       "3         0           0           0           1         0         1   \n",
       "4         1           0           0           1         1         0   \n",
       "\n",
       "   Family_>=3  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
